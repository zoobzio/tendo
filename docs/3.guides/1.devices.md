---
title: Device Management
description: CPU and CUDA device selection, transfers, and best practices
author: zoobzio
published: 2025-12-16
updated: 2025-12-16
tags:
  - Devices
  - CUDA
  - GPU
---

# Device Management

Tendo supports CPU and NVIDIA CUDA GPUs. This guide covers device selection, transfers, and best practices.

## Device Types

```go
type Device struct {
    Type  DeviceType  // CPU or CUDA
    Index int         // GPU index (0 for CPU)
}
```

### Creating Devices

```go
cpu := tendo.CPUDevice()       // CPU
gpu0 := tendo.CUDADevice(0)    // First GPU
gpu1 := tendo.CUDADevice(1)    // Second GPU
```

### Device Properties

```go
device := tendo.CUDADevice(0)

device.Type      // tendo.CUDA
device.Index     // 0
device.IsCPU()   // false
device.IsCUDA()  // true
device.String()  // "cuda:0"
```

## CUDA Availability

Check before using CUDA:

```go
if tendo.IsCUDAAvailable() {
    tendo.SetDefaultDevice(tendo.CUDADevice(0))
} else {
    log.Println("CUDA not available, using CPU")
}
```

### Device Count

```go
count := tendo.CUDADeviceCount()
fmt.Printf("Found %d CUDA devices\n", count)
```

## Default Device

The default device affects tensor creation:

```go
// Get current default
device := tendo.DefaultDevice()  // Initially CPU

// Set default
tendo.SetDefaultDevice(tendo.CUDADevice(0))

// Now all tensors create on GPU by default
t := tendo.Zeros(100, 100)  // On cuda:0
```

### Scoped Device Selection

For temporary device changes, use explicit constructors:

```go
// Default is GPU
tendo.SetDefaultDevice(tendo.CUDADevice(0))

// Create specific tensor on CPU
cpuTensor := tendo.ZerosOn(tendo.CPUDevice(), 100, 100)

// Other tensors still use default (GPU)
gpuTensor := tendo.Zeros(100, 100)
```

## Creating Tensors on Devices

### Explicit Device

All constructors have `*On` variants:

```go
// CPU
cpu := tendo.ZerosOn(tendo.CPUDevice(), 3, 4)

// GPU
gpu := tendo.ZerosOn(tendo.CUDADevice(0), 3, 4)
```

Available constructors:

| Default | Explicit Device |
|---------|-----------------|
| `Zeros` | `ZerosOn` |
| `Ones` | `OnesOn` |
| `Empty` | `EmptyOn` |
| `Full` | `FullOn` |
| `Rand` | `RandOn` |
| `RandN` | `RandNOn` |
| `Eye` | `EyeOn` |
| `FromSlice` | `FromSliceOn` |
| `Arange` | `ArangeOn` |
| `Linspace` | `LinspaceOn` |

### From Existing Tensor

Create tensors matching another's device:

```go
t := tendo.ZerosOn(tendo.CUDADevice(0), 3, 4)

// Same shape, dtype, and device
zeros := tendo.ZerosLike(t)
ones := tendo.OnesLike(t)
empty := tendo.EmptyLike(t)
rand := tendo.RandLike(t)
randN := tendo.RandNLike(t)
```

## Device Transfers

### To CPU

```go
ctx := context.Background()

gpuTensor := tendo.ZerosOn(tendo.CUDADevice(0), 100, 100)
cpuTensor, _ := tendo.ToCPU().Run(ctx, gpuTensor)

cpuTensor.Device().IsCPU()  // true
```

### To CUDA

```go
ctx := context.Background()

cpuTensor := tendo.Zeros(100, 100)
gpuTensor, _ := tendo.ToGPU(0).Run(ctx, cpuTensor)  // To GPU 0

gpuTensor.Device().IsCUDA()  // true
gpuTensor.Device().Index     // 0
```

### Between GPUs

```go
ctx := context.Background()

gpu0 := tendo.ZerosOn(tendo.CUDADevice(0), 100, 100)
gpu1, _ := tendo.ToGPU(1).Run(ctx, gpu0)  // Copy to GPU 1
```

### Using To() for Any Device

```go
ctx := context.Background()

// Move to specific device
device := tendo.CUDADevice(0)
gpuTensor, _ := tendo.To(device).Run(ctx, cpuTensor)
```

### Transfer Events

Transfers emit signals:

```go
capitan.Hook(tendo.TensorTransfer, func(ctx context.Context, e *capitan.Event) {
    from, _ := tendo.KeyFromDevice.From(e)
    to, _ := tendo.KeyToDevice.From(e)
    fmt.Printf("Transfer: %s -> %s\n", from, to)
})
```

## Operation Device Requirements

### Same-Device Operations

Binary operations require tensors on the same device:

```go
ctx := context.Background()

cpu := tendo.Zeros(3, 4)
gpu := tendo.ZerosOn(tendo.CUDADevice(0), 3, 4)

// This returns an error
result, err := tendo.Add(gpu).Run(ctx, cpu)
// err is DeviceMismatchError

// Transfer first
gpuA, _ := tendo.ToGPU(0).Run(ctx, cpu)
result, _ := tendo.Add(gpu).Run(ctx, gpuA)  // OK
```

### Device Checking

```go
ctx := context.Background()

if a.Device() != b.Device() {
    b, _ = tendo.ToGPU(a.Device().Index).Run(ctx, b)
}
result, _ := tendo.Add(b).Run(ctx, a)
```

## Multi-GPU Patterns

### Data Parallelism

Split batch across GPUs:

```go
func parallelForward(ctx context.Context, input *tendo.Tensor, gpuCount int) []*tendo.Tensor {
    batchSize := input.Size(0)
    splitSize := batchSize / gpuCount

    results := make([]*tendo.Tensor, gpuCount)
    var wg sync.WaitGroup

    for i := 0; i < gpuCount; i++ {
        wg.Add(1)
        go func(gpuIdx int) {
            defer wg.Done()

            // Slice batch for this GPU
            start := gpuIdx * splitSize
            end := start + splitSize
            chunk, _ := tendo.Slice(0, start, end).Run(ctx, input)

            // Transfer and compute
            gpuChunk, _ := tendo.ToGPU(gpuIdx).Run(ctx, chunk)
            results[gpuIdx], _ = forward(ctx, gpuChunk)
        }(i)
    }

    wg.Wait()
    return results
}
```

### Model Parallelism

Different layers on different GPUs:

```go
func layeredForward(ctx context.Context, input *tendo.Tensor) (*tendo.Tensor, error) {
    // Layer 1 on GPU 0
    gpu0, _ := tendo.ToGPU(0).Run(ctx, input)
    h1, _ := layer1.Run(ctx, gpu0)

    // Layer 2 on GPU 1
    gpu1, _ := tendo.ToGPU(1).Run(ctx, h1)
    h2, _ := layer2.Run(ctx, gpu1)

    // Output on CPU
    return tendo.ToCPU().Run(ctx, h2)
}
```

## Best Practices

### Minimize Transfers

Transfers are expensive. Batch operations on device:

```go
ctx := context.Background()

// Bad: many small transfers
for _, item := range batch {
    gpu, _ := tendo.ToGPU(0).Run(ctx, item)
    result, _ := process(ctx, gpu)
    cpu, _ := tendo.ToCPU().Run(ctx, result)
    results = append(results, cpu)
}

// Good: transfer once
gpuBatch, _ := tendo.ToGPU(0).Run(ctx, batch)
gpuResults, _ := processBatch(ctx, gpuBatch)
cpuResults, _ := tendo.ToCPU().Run(ctx, gpuResults)
```

### Check Availability Early

```go
func main() {
    // Check at startup
    if !tendo.IsCUDAAvailable() {
        log.Fatal("This application requires CUDA")
    }
    tendo.SetDefaultDevice(tendo.CUDADevice(0))

    // Rest of application uses GPU by default
}
```

### Use Pools for GPU Memory

```go
pool := tendo.NewPool()

// Allocate from pool
storage, _ := tendo.NewCUDAStorageFromPool(1000, tendo.Float32, 0, pool)

// Return to pool when done
storage.Free()  // Goes back to pool, not cudaFree

// Check memory usage
stats := pool.Stats()
fmt.Printf("GPU memory cached: %d bytes\n", stats.CUDABytesCached[0])
```

### Synchronize When Needed

CUDA operations are asynchronous. Synchronize before timing or CPU access:

```go
ctx := context.Background()

gpu := tendo.ZerosOn(tendo.CUDADevice(0), 1000, 1000)

start := time.Now()
result, _ := heavyComputation(ctx, gpu)

// Ensure GPU work is complete before timing
result, _ = tendo.Sync().Run(ctx, result)
elapsed := time.Since(start)
```

## Error Handling

### Device Errors

```go
type DeviceError struct {
    Expected DeviceType
    Got      DeviceType
}

// Raised when operation doesn't support device
result, err := someOp.Run(ctx, cudaTensor)
if err != nil {
    var devErr *tendo.DeviceError
    if errors.As(err, &devErr) {
        // Transfer to supported device
    }
}
```

### Mismatch Errors

```go
type DeviceMismatchError struct {
    A Device
    B Device
}

// Raised for binary ops on different devices
result, err := tendo.Add(cudaTensor).Run(ctx, cpuTensor)
// err is DeviceMismatchError
```

### CUDA Errors

```go
type CUDAError struct {
    Code    int
    Message string
}

// Check CUDA-specific failures
storage, err := tendo.NewCUDAStorage(1000, tendo.Float32, 0)
if err != nil {
    var cudaErr *tendo.CUDAError
    if errors.As(err, &cudaErr) {
        log.Printf("CUDA error %d: %s", cudaErr.Code, cudaErr.Message)
    }
}
```
