---
title: Operations Reference
description: Complete reference for all tensor operations
author: zoobzio
published: 2025-12-16
updated: 2025-12-16
tags:
  - Reference
  - Operations
  - Functions
---

# Operations Reference

Complete reference for tendo tensor operations. All operations return `pipz.Chainable[*Tensor]` and emit capitan signals for observability.

## Usage Pattern

All operations follow the chainable pattern:

```go
// Single operation
result, err := tendo.Add(b).Run(ctx, a)

// Chained operations
result, err := pipz.Chain(
    tendo.Add(bias),
    tendo.ReLU(),
    tendo.MatMul(weights),
).Run(ctx, input)
```

## Element-wise Operations

### Binary Operations

| Function | Description |
|----------|-------------|
| `Add(other *Tensor)` | Element-wise addition |
| `Sub(other *Tensor)` | Element-wise subtraction |
| `Mul(other *Tensor)` | Element-wise multiplication |
| `Div(other *Tensor)` | Element-wise division |

```go
// Add two tensors
result, _ := tendo.Add(b).Run(ctx, a)

// In pipeline
pipeline := pipz.Chain(
    tendo.Add(bias),
    tendo.Mul(scale),
)
```

**Broadcasting:** Supports NumPy-style broadcasting.

```go
a := tendo.Zeros(3, 4)
b := tendo.Zeros(4)
result, _ := tendo.Add(b).Run(ctx, a)  // Shape: [3, 4]
```

### Scalar Operations

| Function | Description |
|----------|-------------|
| `AddScalar(s float32)` | Add scalar to each element |
| `MulScalar(s float32)` | Multiply each element by scalar |
| `Scale(s float32)` | Alias for MulScalar |

```go
// Add 5 to all elements
result, _ := tendo.AddScalar(5).Run(ctx, tensor)

// Scale by 0.5
result, _ := tendo.MulScalar(0.5).Run(ctx, tensor)
```

### Unary Operations

| Function | Description | Formula |
|----------|-------------|---------|
| `Neg()` | Negate | `-x` |
| `Abs()` | Absolute value | `\|x\|` |
| `Exp()` | Exponential | `e^x` |
| `Log()` | Natural logarithm | `ln(x)` |
| `Sqrt()` | Square root | `sqrt(x)` |
| `Square()` | Square | `x^2` |
| `Pow(n float32)` | Power | `x^n` |

```go
// Chain unary operations
pipeline := pipz.Chain(
    tendo.Abs(),
    tendo.Sqrt(),
    tendo.Log(),
)
```

## Matrix Operations

### MatMul

Matrix multiplication.

```go
func MatMul(other *Tensor) pipz.Chainable[*Tensor]
```

**Shapes:**

| a | b | result |
|---|---|--------|
| `[M, K]` | `[K, N]` | `[M, N]` |
| `[B, M, K]` | `[B, K, N]` | `[B, M, N]` |
| `[B, M, K]` | `[K, N]` | `[B, M, N]` |

```go
// 2D matrix multiply
a := tendo.RandN(64, 128)
b := tendo.RandN(128, 32)
c, _ := tendo.MatMul(b).Run(ctx, a)  // Shape: [64, 32]

// Batched matrix multiply
a := tendo.RandN(8, 64, 128)
b := tendo.RandN(8, 128, 32)
c, _ := tendo.MatMul(b).Run(ctx, a)  // Shape: [8, 64, 32]
```

### BatchedMatMul

Alias for MatMul (which already handles batching).

```go
func BatchedMatMul(other *Tensor) pipz.Chainable[*Tensor]
```

### Transpose

Swap two dimensions.

```go
func Transpose(dim0, dim1 int) pipz.Chainable[*Tensor]
```

```go
t := tendo.Zeros(3, 4)
tr, _ := tendo.Transpose(0, 1).Run(ctx, t)  // Shape: [4, 3]

// 3D transpose
t := tendo.Zeros(2, 3, 4)
tr, _ := tendo.Transpose(1, 2).Run(ctx, t)  // Shape: [2, 4, 3]
```

### T

Transpose the last two dimensions. Equivalent to `Transpose(-2, -1)`.

```go
func T() pipz.Chainable[*Tensor]
```

```go
t := tendo.Zeros(2, 3, 4)
tr, _ := tendo.T().Run(ctx, t)  // Shape: [2, 4, 3]
```

## Shape Operations

### Reshape

Change tensor shape without copying data (if contiguous).

```go
func Reshape(shape ...int) pipz.Chainable[*Tensor]
```

```go
t := tendo.Arange(0, 12, 1)           // Shape: [12]
r, _ := tendo.Reshape(3, 4).Run(ctx, t)    // Shape: [3, 4]
r, _ := tendo.Reshape(2, 2, 3).Run(ctx, t) // Shape: [2, 2, 3]

// Use -1 to infer dimension
r, _ := tendo.Reshape(3, -1).Run(ctx, t)   // Shape: [3, 4]
r, _ := tendo.Reshape(-1, 2).Run(ctx, t)   // Shape: [6, 2]
```

### View

Create a view with the given shape. Requires contiguous tensor.

```go
func View(shape ...int) pipz.Chainable[*Tensor]
```

```go
t := tendo.Zeros(12)
v, _ := tendo.View(3, 4).Run(ctx, t)  // Shape: [3, 4]
```

### Flatten

Flatten dimensions from startDim to endDim (inclusive).

```go
func Flatten(startDim, endDim int) pipz.Chainable[*Tensor]
```

```go
t := tendo.Zeros(2, 3, 4)
f, _ := tendo.Flatten(1, 2).Run(ctx, t)  // Shape: [2, 12]
f, _ := tendo.Flatten(0, -1).Run(ctx, t) // Shape: [24]
```

### Squeeze

Remove dimensions of size 1.

```go
func Squeeze(dim ...int) pipz.Chainable[*Tensor]
```

```go
t := tendo.Zeros(1, 3, 1, 4)

// Squeeze specific dimension
s, _ := tendo.Squeeze(0).Run(ctx, t)   // Shape: [3, 1, 4]
s, _ := tendo.Squeeze(2).Run(ctx, t)   // Shape: [1, 3, 4]

// Squeeze all size-1 dimensions
s, _ := tendo.Squeeze().Run(ctx, t)    // Shape: [3, 4]
```

### Unsqueeze

Add a dimension of size 1.

```go
func Unsqueeze(dim int) pipz.Chainable[*Tensor]
```

```go
t := tendo.Zeros(3, 4)
u, _ := tendo.Unsqueeze(0).Run(ctx, t)   // Shape: [1, 3, 4]
u, _ := tendo.Unsqueeze(1).Run(ctx, t)   // Shape: [3, 1, 4]
u, _ := tendo.Unsqueeze(-1).Run(ctx, t)  // Shape: [3, 4, 1]
```

### Slice

Extract a slice along a dimension.

```go
func Slice(dim, start, end int) pipz.Chainable[*Tensor]
```

```go
t := tendo.Arange(0, 10, 1)              // [0, 1, 2, ..., 9]
s, _ := tendo.Slice(0, 2, 5).Run(ctx, t)  // [2, 3, 4]
s, _ := tendo.Slice(0, 0, 3).Run(ctx, t)  // [0, 1, 2]
```

### Narrow

Narrow the tensor along a dimension. Equivalent to `Slice(dim, start, start+length)`.

```go
func Narrow(dim, start, length int) pipz.Chainable[*Tensor]
```

```go
t := tendo.Zeros(10, 5)
n, _ := tendo.Narrow(0, 2, 3).Run(ctx, t)  // Shape: [3, 5]
```

### Expand

Broadcast tensor to a larger shape.

```go
func Expand(shape ...int) pipz.Chainable[*Tensor]
```

```go
t := tendo.Zeros(1, 4)
e, _ := tendo.Expand(3, 4).Run(ctx, t)   // Shape: [3, 4] (broadcast)
```

### Permute

Reorder all dimensions.

```go
func Permute(dims ...int) pipz.Chainable[*Tensor]
```

```go
t := tendo.Zeros(2, 3, 4)
p, _ := tendo.Permute(2, 0, 1).Run(ctx, t)  // Shape: [4, 2, 3]
```

## Reduction Operations

All reductions support negative indexing (`-1` = last dimension).

| Function | Description |
|----------|-------------|
| `Sum(dims ...int)` | Sum along dimensions (variadic) |
| `Mean(dims ...int)` | Mean along dimensions (variadic) |
| `Max(dim int)` | Maximum along dimension |
| `Min(dim int)` | Minimum along dimension |
| `ArgMax(dim int)` | Index of maximum |
| `ArgMin(dim int)` | Index of minimum |

```go
t := tendo.FromSlice([]float32{1, 2, 3, 4, 5, 6}, 2, 3)
// [[1, 2, 3],
//  [4, 5, 6]]

sum, _ := tendo.Sum(-1).Run(ctx, t)     // [6, 15]     (sum rows)
sum, _ := tendo.Sum(0).Run(ctx, t)      // [5, 7, 9]   (sum columns)
mean, _ := tendo.Mean(-1).Run(ctx, t)   // [2, 5]      (mean of rows)
max, _ := tendo.Max(-1).Run(ctx, t)     // [3, 6]      (max of rows)
argmax, _ := tendo.ArgMax(-1).Run(ctx, t) // [2, 2]    (index of max)
```

### Global Reduction

Reduce all dimensions by calling with no arguments:

```go
t := tendo.FromSlice([]float32{1, 2, 3, 4}, 2, 2)
total, _ := tendo.Sum().Run(ctx, t)   // Scalar: 10
avg, _ := tendo.Mean().Run(ctx, t)    // Scalar: 2.5
```

## Activation Functions

### ReLU

```go
func ReLU() pipz.Chainable[*Tensor]
```

`ReLU(x) = max(0, x)`

### Sigmoid

```go
func Sigmoid() pipz.Chainable[*Tensor]
```

`Sigmoid(x) = 1 / (1 + exp(-x))`

### Tanh

```go
func Tanh() pipz.Chainable[*Tensor]
```

`Tanh(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))`

### GELU

```go
func GELU() pipz.Chainable[*Tensor]
```

`GELU(x) = x * 0.5 * (1 + erf(x / sqrt(2)))`

### SiLU (Swish)

```go
func SiLU() pipz.Chainable[*Tensor]
```

`SiLU(x) = x * sigmoid(x)`

### LeakyReLU

```go
func LeakyReLU(negativeSlope float32) pipz.Chainable[*Tensor]
```

`LeakyReLU(x) = x if x > 0 else negativeSlope * x`

```go
result, _ := tendo.LeakyReLU(0.01).Run(ctx, t)
```

### Softmax

```go
func Softmax(dim int) pipz.Chainable[*Tensor]
```

`Softmax(x)_i = exp(x_i) / sum(exp(x_j))`

```go
logits := tendo.RandN(8, 10)  // Batch of 8, 10 classes
probs, _ := tendo.Softmax(-1).Run(ctx, logits)  // Softmax over classes
```

### LogSoftmax

```go
func LogSoftmax(dim int) pipz.Chainable[*Tensor]
```

`LogSoftmax(x)_i = x_i - log(sum(exp(x_j)))`

More numerically stable than `Log(Softmax(x))`.

### Dropout

```go
func Dropout(p float32) pipz.Chainable[*Tensor]
```

Randomly zeros elements with probability `p` during training. Scales output by `1/(1-p)`.

```go
// Training mode
ctx := tendo.WithTraining(context.Background())
result, _ := tendo.Dropout(0.5).Run(ctx, input)

// Inference mode (no-op)
ctx := tendo.WithInference(context.Background())
result, _ := tendo.Dropout(0.5).Run(ctx, input)
```

## Convolution Operations

### Conv2d

2D convolution with configuration struct.

```go
func Conv2d(weight *Tensor, config Conv2dConfig) pipz.Chainable[*Tensor]

type Conv2dConfig struct {
    Padding  [2]int // [padH, padW]
    Stride   [2]int // [strideH, strideW]
    Dilation [2]int // [dilationH, dilationW]
    Groups   int    // number of groups for grouped convolution
}
```

**Shapes:**

| Parameter | Shape |
|-----------|-------|
| input | `[N, C_in, H, W]` |
| weight | `[C_out, C_in/groups, kH, kW]` |
| output | `[N, C_out, H_out, W_out]` |

```go
input := tendo.RandN(1, 3, 28, 28)      // [batch, channels, height, width]
weight := tendo.RandN(16, 3, 3, 3)      // [out_channels, in_channels, kH, kW]

config := tendo.Conv2dConfig{
    Padding:  [2]int{1, 1},
    Stride:   [2]int{1, 1},
    Dilation: [2]int{1, 1},
    Groups:   1,
}

output, _ := tendo.Conv2d(weight, config).Run(ctx, input)
// Output shape: [1, 16, 28, 28]
```

### Conv2dSimple

Convenience function with same padding to preserve spatial dimensions.

```go
func Conv2dSimple(weight *Tensor, stride int) pipz.Chainable[*Tensor]
```

```go
weight := tendo.RandN(16, 3, 3, 3)
output, _ := tendo.Conv2dSimple(weight, 1).Run(ctx, input)
```

### Depthwise Convolution

Use `Groups` equal to input channels:

```go
// Depthwise convolution (groups = in_channels)
input := tendo.RandN(1, 32, 28, 28)
weight := tendo.RandN(32, 1, 3, 3)  // [out, in/groups, kH, kW]

config := tendo.Conv2dConfig{
    Padding: [2]int{1, 1},
    Stride:  [2]int{1, 1},
    Dilation: [2]int{1, 1},
    Groups:  32,
}

output, _ := tendo.Conv2d(weight, config).Run(ctx, input)
```

## Device Operations

### To

Move tensor to specified device.

```go
func To(device Device) pipz.Chainable[*Tensor]
```

### ToCPU

Move tensor to CPU.

```go
func ToCPU() pipz.Chainable[*Tensor]
```

### ToGPU

Move tensor to specified GPU.

```go
func ToGPU(index int) pipz.Chainable[*Tensor]
```

```go
// Move to GPU 0
gpu, _ := tendo.ToGPU(0).Run(ctx, cpuTensor)

// Move back to CPU
cpu, _ := tendo.ToCPU().Run(ctx, gpuTensor)
```

### MakeContiguous

Ensure tensor is contiguous in memory.

```go
func MakeContiguous() pipz.Chainable[*Tensor]
```

### Sync

Synchronize device (blocks until CUDA operations complete).

```go
func Sync() pipz.Chainable[*Tensor]
```

### Pin / Unpin

Pin/unpin memory for faster CPU-GPU transfer (placeholder for future implementation).

```go
func Pin() pipz.Chainable[*Tensor]
func Unpin() pipz.Chainable[*Tensor]
```

## Type Operations

### DType Conversion

```go
func ToFloat32() pipz.Chainable[*Tensor]
func ToFloat16() pipz.Chainable[*Tensor]
func ToBFloat16() pipz.Chainable[*Tensor]
func ToDType(dtype DType) pipz.Chainable[*Tensor]

// Aliases
func Float() pipz.Chainable[*Tensor]   // ToFloat32
func Half() pipz.Chainable[*Tensor]    // ToFloat16
func BFloat() pipz.Chainable[*Tensor]  // ToBFloat16
```

```go
// Convert to half precision
half, _ := tendo.Half().Run(ctx, tensor)

// Convert to specific dtype
converted, _ := tendo.ToDType(tendo.BFloat16).Run(ctx, tensor)
```

## Operation Summary

| Category | Operations |
|----------|------------|
| Element-wise | `Add`, `Sub`, `Mul`, `Div`, `AddScalar`, `MulScalar`, `Scale`, `Neg`, `Abs`, `Exp`, `Log`, `Sqrt`, `Square`, `Pow` |
| Matrix | `MatMul`, `BatchedMatMul`, `Transpose`, `T` |
| Shape | `Reshape`, `View`, `Flatten`, `Squeeze`, `Unsqueeze`, `Slice`, `Narrow`, `Expand`, `Permute` |
| Reduction | `Sum`, `Mean`, `Max`, `Min`, `ArgMax`, `ArgMin` |
| Activation | `ReLU`, `Sigmoid`, `Tanh`, `GELU`, `SiLU`, `LeakyReLU`, `Softmax`, `LogSoftmax`, `Dropout` |
| Convolution | `Conv2d`, `Conv2dSimple` |
| Device | `To`, `ToCPU`, `ToGPU`, `MakeContiguous`, `Sync`, `Pin`, `Unpin` |
| DType | `ToFloat32`, `ToFloat16`, `ToBFloat16`, `ToDType`, `Float`, `Half`, `BFloat` |
